{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3775539/402818368.py:8: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  books = pd.read_csv(input_dir + 'BX-Books.csv', sep=';', encoding=\"latin-1\", error_bad_lines=False)\n",
      "Skipping line 6452: expected 8 fields, saw 9\n",
      "Skipping line 43667: expected 8 fields, saw 10\n",
      "Skipping line 51751: expected 8 fields, saw 9\n",
      "\n",
      "Skipping line 92038: expected 8 fields, saw 9\n",
      "Skipping line 104319: expected 8 fields, saw 9\n",
      "Skipping line 121768: expected 8 fields, saw 9\n",
      "\n",
      "Skipping line 144058: expected 8 fields, saw 9\n",
      "Skipping line 150789: expected 8 fields, saw 9\n",
      "Skipping line 157128: expected 8 fields, saw 9\n",
      "Skipping line 180189: expected 8 fields, saw 9\n",
      "Skipping line 185738: expected 8 fields, saw 9\n",
      "\n",
      "Skipping line 209388: expected 8 fields, saw 9\n",
      "Skipping line 220626: expected 8 fields, saw 9\n",
      "Skipping line 227933: expected 8 fields, saw 11\n",
      "Skipping line 228957: expected 8 fields, saw 10\n",
      "Skipping line 245933: expected 8 fields, saw 9\n",
      "Skipping line 251296: expected 8 fields, saw 9\n",
      "Skipping line 259941: expected 8 fields, saw 9\n",
      "Skipping line 261529: expected 8 fields, saw 9\n",
      "\n",
      "/tmp/ipykernel_3775539/402818368.py:8: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(input_dir + 'BX-Books.csv', sep=';', encoding=\"latin-1\", error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_dir = 'raw_data/'\n",
    "output_dir = 'processed_data/'\n",
    "\n",
    "interactions = pd.read_csv(input_dir + 'BX-Book-Ratings.csv', sep=';', encoding=\"latin-1\")\n",
    "# users = pd.read_csv(input_dir + 'BX-Users.csv', sep=';', encoding=\"latin-1\")\n",
    "books = pd.read_csv(input_dir + 'BX-Books.csv', sep=';', encoding=\"latin-1\", error_bad_lines=False)\n",
    "interactions_all = pd.merge(interactions, books, on='ISBN', how='inner')\n",
    "interactions_all.to_csv(output_dir + 'interactions_all.csv', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031131</th>\n",
       "      <td>276688</td>\n",
       "      <td>0517145553</td>\n",
       "      <td>0</td>\n",
       "      <td>Mostly Harmless</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>1995</td>\n",
       "      <td>Random House Value Pub</td>\n",
       "      <td>http://images.amazon.com/images/P/0517145553.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0517145553.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0517145553.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276688</td>\n",
       "      <td>1575660792</td>\n",
       "      <td>7</td>\n",
       "      <td>Gray Matter</td>\n",
       "      <td>Shirley Kennett</td>\n",
       "      <td>1996</td>\n",
       "      <td>Kensington Publishing Corporation</td>\n",
       "      <td>http://images.amazon.com/images/P/1575660792.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1575660792.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1575660792.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>276690</td>\n",
       "      <td>0590907301</td>\n",
       "      <td>0</td>\n",
       "      <td>Triplet Trouble and the Class Trip (Triplet Tr...</td>\n",
       "      <td>Debbie Dadey</td>\n",
       "      <td>1997</td>\n",
       "      <td>Apple</td>\n",
       "      <td>http://images.amazon.com/images/P/0590907301.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590907301.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0590907301.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031134</th>\n",
       "      <td>276704</td>\n",
       "      <td>0679752714</td>\n",
       "      <td>0</td>\n",
       "      <td>A Desert of Pure Feeling (Vintage Contemporaries)</td>\n",
       "      <td>Judith Freeman</td>\n",
       "      <td>1997</td>\n",
       "      <td>Vintage Books USA</td>\n",
       "      <td>http://images.amazon.com/images/P/0679752714.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0679752714.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0679752714.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031135</th>\n",
       "      <td>276704</td>\n",
       "      <td>0806917695</td>\n",
       "      <td>5</td>\n",
       "      <td>Perplexing Lateral Thinking Puzzles: Scholasti...</td>\n",
       "      <td>Paul Sloane</td>\n",
       "      <td>1997</td>\n",
       "      <td>Sterling Publishing</td>\n",
       "      <td>http://images.amazon.com/images/P/0806917695.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0806917695.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0806917695.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031136 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID        ISBN  Book-Rating  \\\n",
       "0         276725  034545104X            0   \n",
       "1           2313  034545104X            5   \n",
       "2           6543  034545104X            0   \n",
       "3           8680  034545104X            5   \n",
       "4          10314  034545104X            9   \n",
       "...          ...         ...          ...   \n",
       "1031131   276688  0517145553            0   \n",
       "1031132   276688  1575660792            7   \n",
       "1031133   276690  0590907301            0   \n",
       "1031134   276704  0679752714            0   \n",
       "1031135   276704  0806917695            5   \n",
       "\n",
       "                                                Book-Title      Book-Author  \\\n",
       "0                                     Flesh Tones: A Novel       M. J. Rose   \n",
       "1                                     Flesh Tones: A Novel       M. J. Rose   \n",
       "2                                     Flesh Tones: A Novel       M. J. Rose   \n",
       "3                                     Flesh Tones: A Novel       M. J. Rose   \n",
       "4                                     Flesh Tones: A Novel       M. J. Rose   \n",
       "...                                                    ...              ...   \n",
       "1031131                                    Mostly Harmless    Douglas Adams   \n",
       "1031132                                        Gray Matter  Shirley Kennett   \n",
       "1031133  Triplet Trouble and the Class Trip (Triplet Tr...     Debbie Dadey   \n",
       "1031134  A Desert of Pure Feeling (Vintage Contemporaries)   Judith Freeman   \n",
       "1031135  Perplexing Lateral Thinking Puzzles: Scholasti...      Paul Sloane   \n",
       "\n",
       "        Year-Of-Publication                          Publisher  \\\n",
       "0                      2002                   Ballantine Books   \n",
       "1                      2002                   Ballantine Books   \n",
       "2                      2002                   Ballantine Books   \n",
       "3                      2002                   Ballantine Books   \n",
       "4                      2002                   Ballantine Books   \n",
       "...                     ...                                ...   \n",
       "1031131                1995             Random House Value Pub   \n",
       "1031132                1996  Kensington Publishing Corporation   \n",
       "1031133                1997                              Apple   \n",
       "1031134                1997                  Vintage Books USA   \n",
       "1031135                1997                Sterling Publishing   \n",
       "\n",
       "                                               Image-URL-S  \\\n",
       "0        http://images.amazon.com/images/P/034545104X.0...   \n",
       "1        http://images.amazon.com/images/P/034545104X.0...   \n",
       "2        http://images.amazon.com/images/P/034545104X.0...   \n",
       "3        http://images.amazon.com/images/P/034545104X.0...   \n",
       "4        http://images.amazon.com/images/P/034545104X.0...   \n",
       "...                                                    ...   \n",
       "1031131  http://images.amazon.com/images/P/0517145553.0...   \n",
       "1031132  http://images.amazon.com/images/P/1575660792.0...   \n",
       "1031133  http://images.amazon.com/images/P/0590907301.0...   \n",
       "1031134  http://images.amazon.com/images/P/0679752714.0...   \n",
       "1031135  http://images.amazon.com/images/P/0806917695.0...   \n",
       "\n",
       "                                               Image-URL-M  \\\n",
       "0        http://images.amazon.com/images/P/034545104X.0...   \n",
       "1        http://images.amazon.com/images/P/034545104X.0...   \n",
       "2        http://images.amazon.com/images/P/034545104X.0...   \n",
       "3        http://images.amazon.com/images/P/034545104X.0...   \n",
       "4        http://images.amazon.com/images/P/034545104X.0...   \n",
       "...                                                    ...   \n",
       "1031131  http://images.amazon.com/images/P/0517145553.0...   \n",
       "1031132  http://images.amazon.com/images/P/1575660792.0...   \n",
       "1031133  http://images.amazon.com/images/P/0590907301.0...   \n",
       "1031134  http://images.amazon.com/images/P/0679752714.0...   \n",
       "1031135  http://images.amazon.com/images/P/0806917695.0...   \n",
       "\n",
       "                                               Image-URL-L  \n",
       "0        http://images.amazon.com/images/P/034545104X.0...  \n",
       "1        http://images.amazon.com/images/P/034545104X.0...  \n",
       "2        http://images.amazon.com/images/P/034545104X.0...  \n",
       "3        http://images.amazon.com/images/P/034545104X.0...  \n",
       "4        http://images.amazon.com/images/P/034545104X.0...  \n",
       "...                                                    ...  \n",
       "1031131  http://images.amazon.com/images/P/0517145553.0...  \n",
       "1031132  http://images.amazon.com/images/P/1575660792.0...  \n",
       "1031133  http://images.amazon.com/images/P/0590907301.0...  \n",
       "1031134  http://images.amazon.com/images/P/0679752714.0...  \n",
       "1031135  http://images.amazon.com/images/P/0806917695.0...  \n",
       "\n",
       "[1031136 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149779</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID         ISBN  Book-Rating\n",
       "0         276725   034545104X            0\n",
       "1         276726   0155061224            5\n",
       "2         276727   0446520802            0\n",
       "3         276729   052165615X            3\n",
       "4         276729   0521795028            6\n",
       "...          ...          ...          ...\n",
       "1149775   276704   1563526298            9\n",
       "1149776   276706   0679447156            0\n",
       "1149777   276709   0515107662           10\n",
       "1149778   276721   0590442449           10\n",
       "1149779   276723  05162443314            8\n",
       "\n",
       "[1149780 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = pd.read_csv(input_dir + 'BX-Book-Ratings.csv', sep=';', encoding=\"latin-1\")\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_core(df, column_name, k):\n",
    "    # filter out rows with less than k occurrences baed on the column_name\n",
    "    value_counts = df[column_name].value_counts()\n",
    "    to_remove = value_counts[value_counts < k].index\n",
    "    df = df[~df[column_name].isin(to_remove)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5386"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions = pd.read_csv(input_dir + 'BX-Book-Ratings.csv', sep=';', encoding=\"latin-1\")\n",
    "\n",
    "interactions = k_core(interactions, 'User-ID', 20)\n",
    "interactions = k_core(interactions, 'ISBN', 20)\n",
    "interactions = interactions.reset_index(drop=True)\n",
    "interactions = interactions[interactions['ISBN'].isin(books['ISBN'])]\n",
    "\n",
    "interactions['ISBN'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5386"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = books[books['ISBN'].isin(interactions['ISBN'])]\n",
    "books.ISBN.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1999</td>\n",
       "      <td>Dell</td>\n",
       "      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Beloved (Plume Contemporary Fiction)</td>\n",
       "      <td>Toni Morrison</td>\n",
       "      <td>1994</td>\n",
       "      <td>Plume</td>\n",
       "      <td>http://images.amazon.com/images/P/0452264464.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0452264464.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0452264464.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1841721522</td>\n",
       "      <td>New Vegetarian: Bold and Beautiful Recipes for...</td>\n",
       "      <td>Celia Brooks Brown</td>\n",
       "      <td>2001</td>\n",
       "      <td>Ryland Peters &amp;amp; Small Ltd</td>\n",
       "      <td>http://images.amazon.com/images/P/1841721522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1841721522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1841721522.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0971880107</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>Rich Shapero</td>\n",
       "      <td>2004</td>\n",
       "      <td>Too Far</td>\n",
       "      <td>http://images.amazon.com/images/P/0971880107.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0971880107.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0971880107.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ISBN                                         Book-Title  \\\n",
       "5   0399135782                             The Kitchen God's Wife   \n",
       "18  0440234743                                      The Testament   \n",
       "19  0452264464               Beloved (Plume Contemporary Fiction)   \n",
       "21  1841721522  New Vegetarian: Bold and Beautiful Recipes for...   \n",
       "26  0971880107                                        Wild Animus   \n",
       "\n",
       "           Book-Author Year-Of-Publication                      Publisher  \\\n",
       "5              Amy Tan                1991               Putnam Pub Group   \n",
       "18        John Grisham                1999                           Dell   \n",
       "19       Toni Morrison                1994                          Plume   \n",
       "21  Celia Brooks Brown                2001  Ryland Peters &amp; Small Ltd   \n",
       "26        Rich Shapero                2004                        Too Far   \n",
       "\n",
       "                                          Image-URL-S  \\\n",
       "5   http://images.amazon.com/images/P/0399135782.0...   \n",
       "18  http://images.amazon.com/images/P/0440234743.0...   \n",
       "19  http://images.amazon.com/images/P/0452264464.0...   \n",
       "21  http://images.amazon.com/images/P/1841721522.0...   \n",
       "26  http://images.amazon.com/images/P/0971880107.0...   \n",
       "\n",
       "                                          Image-URL-M  \\\n",
       "5   http://images.amazon.com/images/P/0399135782.0...   \n",
       "18  http://images.amazon.com/images/P/0440234743.0...   \n",
       "19  http://images.amazon.com/images/P/0452264464.0...   \n",
       "21  http://images.amazon.com/images/P/1841721522.0...   \n",
       "26  http://images.amazon.com/images/P/0971880107.0...   \n",
       "\n",
       "                                          Image-URL-L  \n",
       "5   http://images.amazon.com/images/P/0399135782.0...  \n",
       "18  http://images.amazon.com/images/P/0440234743.0...  \n",
       "19  http://images.amazon.com/images/P/0452264464.0...  \n",
       "21  http://images.amazon.com/images/P/1841721522.0...  \n",
       "26  http://images.amazon.com/images/P/0971880107.0...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv('processed_data/books_raw_20core.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.merge(interactions, books, on='ISBN', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276762</td>\n",
       "      <td>0380711524</td>\n",
       "      <td>5</td>\n",
       "      <td>See Jane Run</td>\n",
       "      <td>Joy Fielding</td>\n",
       "      <td>1992</td>\n",
       "      <td>Avon</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7158</td>\n",
       "      <td>0380711524</td>\n",
       "      <td>0</td>\n",
       "      <td>See Jane Run</td>\n",
       "      <td>Joy Fielding</td>\n",
       "      <td>1992</td>\n",
       "      <td>Avon</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23768</td>\n",
       "      <td>0380711524</td>\n",
       "      <td>0</td>\n",
       "      <td>See Jane Run</td>\n",
       "      <td>Joy Fielding</td>\n",
       "      <td>1992</td>\n",
       "      <td>Avon</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28204</td>\n",
       "      <td>0380711524</td>\n",
       "      <td>9</td>\n",
       "      <td>See Jane Run</td>\n",
       "      <td>Joy Fielding</td>\n",
       "      <td>1992</td>\n",
       "      <td>Avon</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36606</td>\n",
       "      <td>0380711524</td>\n",
       "      <td>0</td>\n",
       "      <td>See Jane Run</td>\n",
       "      <td>Joy Fielding</td>\n",
       "      <td>1992</td>\n",
       "      <td>Avon</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0380711524.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating    Book-Title   Book-Author  \\\n",
       "0   276762  0380711524            5  See Jane Run  Joy Fielding   \n",
       "1     7158  0380711524            0  See Jane Run  Joy Fielding   \n",
       "2    23768  0380711524            0  See Jane Run  Joy Fielding   \n",
       "3    28204  0380711524            9  See Jane Run  Joy Fielding   \n",
       "4    36606  0380711524            0  See Jane Run  Joy Fielding   \n",
       "\n",
       "  Year-Of-Publication Publisher  \\\n",
       "0                1992      Avon   \n",
       "1                1992      Avon   \n",
       "2                1992      Avon   \n",
       "3                1992      Avon   \n",
       "4                1992      Avon   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0380711524.0...   \n",
       "1  http://images.amazon.com/images/P/0380711524.0...   \n",
       "2  http://images.amazon.com/images/P/0380711524.0...   \n",
       "3  http://images.amazon.com/images/P/0380711524.0...   \n",
       "4  http://images.amazon.com/images/P/0380711524.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0380711524.0...   \n",
       "1  http://images.amazon.com/images/P/0380711524.0...   \n",
       "2  http://images.amazon.com/images/P/0380711524.0...   \n",
       "3  http://images.amazon.com/images/P/0380711524.0...   \n",
       "4  http://images.amazon.com/images/P/0380711524.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0380711524.0...  \n",
       "1  http://images.amazon.com/images/P/0380711524.0...  \n",
       "2  http://images.amazon.com/images/P/0380711524.0...  \n",
       "3  http://images.amazon.com/images/P/0380711524.0...  \n",
       "4  http://images.amazon.com/images/P/0380711524.0...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# books = books[['ISBN', 'Book-Title']]\n",
    "# books.columns = ['book_id', 'book_title']\n",
    "# # books.to_csv(output_dir + 'item_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6975"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_titles = books['Book-Title'].tolist()\n",
    "book_ids = books['ISBN'].tolist()\n",
    "book_dict = dict(zip(book_ids, book_titles))\n",
    "interaction_dicts = dict()\n",
    "\n",
    "for i in range(len(interactions)):\n",
    "    user_id = interactions['User-ID'][i]\n",
    "    book_id = interactions['ISBN'][i]\n",
    "    rating = interactions['Book-Rating'][i]\n",
    "    book_title = interactions['Book-Title'][i]\n",
    "    book_author = interactions['Book-Author'][i]\n",
    "    book_year = interactions['Year-Of-Publication'][i]\n",
    "\n",
    "    if user_id not in interaction_dicts:\n",
    "        interaction_dicts[user_id] = {\n",
    "            'book_id': [],\n",
    "            'rating': [],\n",
    "            'book_title': [],\n",
    "            'book_author': [],\n",
    "            'book_year': []\n",
    "        }\n",
    "    interaction_dicts[user_id]['book_id'].append(book_id)\n",
    "    interaction_dicts[user_id]['rating'].append(int(int(rating) > 5))\n",
    "    interaction_dicts[user_id]['book_title'].append(book_title)\n",
    "    interaction_dicts[user_id]['book_author'].append(book_author)\n",
    "    interaction_dicts[user_id]['book_year'].append(book_year)\n",
    "\n",
    "len(interaction_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed_data/interactions_20core.csv', 'w') as f:\n",
    "    import csv\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'book_id', 'rating', 'book_title', 'book_author', 'book_year'])\n",
    "    for user_id, user_dict in interaction_dicts.items():\n",
    "        writer.writerow([user_id, user_dict['book_id'], user_dict['rating'], user_dict['book_title'], user_dict['book_author'], user_dict['book_year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_mapping.csv saved\n"
     ]
    }
   ],
   "source": [
    "if len(book_titles) == len(book_ids):\n",
    "    with open('processed_data/item_mapping.csv', 'w') as f:\n",
    "        import csv\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['book_id', 'book_title'])\n",
    "        for i in range(len(book_titles)):\n",
    "            writer.writerow([book_ids[i], book_titles[i]])\n",
    "    print('item_mapping.csv saved')\n",
    "else:\n",
    "    print('Error: book titles and ids do not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4441"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the user with less than 11 interactions\n",
    "\n",
    "new_user_dict = {}\n",
    "for key in interaction_dicts.keys():\n",
    "    if len(interaction_dicts[key]['book_id'])  >= 11:\n",
    "        new_user_dict[key] = interaction_dicts[key]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "len(new_user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5386"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the length of unique book_id for all records in filtered_interaction_dicts\n",
    "unique_book_ids = set()\n",
    "for key, values in new_user_dict.items():\n",
    "    unique_book_ids.update(set(values['book_id']))\n",
    "len(unique_book_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198360\n"
     ]
    }
   ],
   "source": [
    "sequential_interaction_list = []\n",
    "seq_len = 10\n",
    "for user_id in new_user_dict:\n",
    "    temp = zip(new_user_dict[user_id]['book_id'], new_user_dict[user_id]['rating'], new_user_dict[user_id]['book_title'], new_user_dict[user_id]['book_author'])\n",
    "    result = zip(*temp)\n",
    "    new_user_dict[user_id]['book_id'], new_user_dict[user_id]['rating'], new_user_dict[user_id]['book_title'], new_user_dict[user_id]['book_author'] = [list(_) for _ in result]\n",
    "    for i in range(10, len(new_user_dict[user_id]['book_id'])):\n",
    "        sequential_interaction_list.append(\n",
    "            [user_id, new_user_dict[user_id]['book_title'][i - seq_len: i],\n",
    "             new_user_dict[user_id]['book_id'][i-seq_len:i], \n",
    "             new_user_dict[user_id]['rating'][i-seq_len:i],  \n",
    "             new_user_dict[user_id]['book_id'][i], \n",
    "             new_user_dict[user_id]['book_title'][i],\n",
    "             new_user_dict[user_id]['rating'][i]]\n",
    "        )\n",
    "print(len(sequential_interaction_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('processed_data/all_sequential.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['user_id', 'history_item_title', 'history_item_id', 'history_rating', 'item_id', 'item_title', 'rating'])\n",
    "    writer.writerows(sequential_interaction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4921"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(sequential_interaction_list)\n",
    "sequential_interaction_list_2000 = sequential_interaction_list[:2000]\n",
    "unique_book_ids = set()\n",
    "for record in sequential_interaction_list_2000:\n",
    "    unique_book_ids.update(set(record[2]))\n",
    "len(unique_book_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "user_list = list(new_user_dict.keys())\n",
    "random.seed(42)\n",
    "random.shuffle(user_list)\n",
    "user_2000 = user_list[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "nrows = []\n",
    "for user in user_2000:\n",
    "\n",
    "    item_id = new_user_dict[user]['book_id']\n",
    "    rating = new_user_dict[user]['rating']\n",
    "    book_title = new_user_dict[user]['book_title']\n",
    "    book_author = new_user_dict[user]['book_author']\n",
    "\n",
    "    random.seed(42)\n",
    "    random.shuffle(item_id)\n",
    "    random.seed(42)\n",
    "    random.shuffle(rating)\n",
    "    random.seed(42)\n",
    "    random.shuffle(book_title)\n",
    "    random.seed(42)\n",
    "    random.shuffle(book_author)\n",
    "\n",
    "    nrows.append([user, item_id[:-1][:10], book_title[:-1][:10], book_author[:-1][:10], rating[:-1][:10], item_id[-1], rating[-1]])\n",
    "\n",
    "len(nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4389"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_book_ids = set()\n",
    "for record in nrows:\n",
    "    unique_book_ids.update(set(record[2]))\n",
    "len(unique_book_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_csv(user_list, user_dict, output_csv):\n",
    "    import random\n",
    "    nrows = []\n",
    "    for user in user_list:\n",
    "\n",
    "        book_id = user_dict[user]['book_id']\n",
    "        rating = user_dict[user]['rating']\n",
    "        book_title = user_dict[user]['book_title']\n",
    "        book_author = user_dict[user]['book_author']\n",
    "\n",
    "        random.seed(42)\n",
    "        random.shuffle(item_id)\n",
    "        random.seed(42)\n",
    "        random.shuffle(rating)\n",
    "        random.seed(42)\n",
    "        random.shuffle(book_title)\n",
    "        random.seed(42)\n",
    "        random.shuffle(book_author)\n",
    "\n",
    "        nrows.append([user, book_id[:-1][:10], book_title[:-1][:10], book_author[:-1][:10], rating[:-1][:10], book_id[-1], book_title[-1], rating[-1]])\n",
    "\n",
    "    with open(output_csv, 'w') as f:\n",
    "        import csv\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['user_id', 'history_item_id', 'history_item_title', 'history_item_author', 'history_rating','item_id','item_title', 'rating'])\n",
    "        writer.writerows(nrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_csv(user_2000, new_user_dict, 'processed_data/data_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after using chatgpt to generate the taxonomy, \n",
    "# randomly sample some instances from the dataset to test if the taxonomy can cover the sampled instances\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('processed_data/books_raw_20core.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1999</td>\n",
       "      <td>Dell</td>\n",
       "      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Beloved (Plume Contemporary Fiction)</td>\n",
       "      <td>Toni Morrison</td>\n",
       "      <td>1994</td>\n",
       "      <td>Plume</td>\n",
       "      <td>http://images.amazon.com/images/P/0452264464.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0452264464.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0452264464.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1841721522</td>\n",
       "      <td>New Vegetarian: Bold and Beautiful Recipes for...</td>\n",
       "      <td>Celia Brooks Brown</td>\n",
       "      <td>2001</td>\n",
       "      <td>Ryland Peters &amp;amp; Small Ltd</td>\n",
       "      <td>http://images.amazon.com/images/P/1841721522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1841721522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1841721522.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0971880107</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>Rich Shapero</td>\n",
       "      <td>2004</td>\n",
       "      <td>Too Far</td>\n",
       "      <td>http://images.amazon.com/images/P/0971880107.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0971880107.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0971880107.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0399135782                             The Kitchen God's Wife   \n",
       "1  0440234743                                      The Testament   \n",
       "2  0452264464               Beloved (Plume Contemporary Fiction)   \n",
       "3  1841721522  New Vegetarian: Bold and Beautiful Recipes for...   \n",
       "4  0971880107                                        Wild Animus   \n",
       "\n",
       "          Book-Author  Year-Of-Publication                      Publisher  \\\n",
       "0             Amy Tan                 1991               Putnam Pub Group   \n",
       "1        John Grisham                 1999                           Dell   \n",
       "2       Toni Morrison                 1994                          Plume   \n",
       "3  Celia Brooks Brown                 2001  Ryland Peters &amp; Small Ltd   \n",
       "4        Rich Shapero                 2004                        Too Far   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0399135782.0...   \n",
       "1  http://images.amazon.com/images/P/0440234743.0...   \n",
       "2  http://images.amazon.com/images/P/0452264464.0...   \n",
       "3  http://images.amazon.com/images/P/1841721522.0...   \n",
       "4  http://images.amazon.com/images/P/0971880107.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0399135782.0...   \n",
       "1  http://images.amazon.com/images/P/0440234743.0...   \n",
       "2  http://images.amazon.com/images/P/0452264464.0...   \n",
       "3  http://images.amazon.com/images/P/1841721522.0...   \n",
       "4  http://images.amazon.com/images/P/0971880107.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0399135782.0...  \n",
       "1  http://images.amazon.com/images/P/0440234743.0...  \n",
       "2  http://images.amazon.com/images/P/0452264464.0...  \n",
       "3  http://images.amazon.com/images/P/1841721522.0...  \n",
       "4  http://images.amazon.com/images/P/0971880107.0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']]\n",
    "books.columns = ['book_id', 'book_title', 'book_author', 'book_year', 'publisher']\n",
    "books.to_csv('processed_data/books.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# randomly sample 40 records from the books dataframe and store them in four groups of 10 records\n",
    "sampled_books = books.sample(40, replace=False, random_state=seed)\n",
    "\n",
    "random_samples = []\n",
    "for i in range(4):\n",
    "    random_samples.append(sampled_books[i*10: (i+1)*10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book_id,book_title,book_author,book_year,publisher\n",
      "0671019759,Dream Man,Linda Howard,1998,Pocket\n",
      "0312989393,Queen Bee of Mimosa Branch,Haywood Smith,2003,St. Martin's Paperbacks\n",
      "0786880007,Simplify Your Life : 100 Ways to Slow Down and Enjoy the Things That Really Matter,Elaine St. James,1994,Hyperion\n",
      "0449911004,Patty Jane's House of Curl (Ballantine Reader's Circle),LORNA LANDVIK,1996,Ballantine Books\n",
      "0380790076,Simply Irresistible (Avon Light Contemporary Romances),Rachel Gibson,1998,Avon\n",
      "0385491034,The Robber Bride,MARGARET ATWOOD,1998,Anchor\n",
      "0449911357,Fried Green Tomatoes at the Whistle Stop Cafe (Ballantine Reader's Circle),Fannie Flagg,1997,Ballantine Books\n",
      "0449912558,The Sparrow,MARY DORIA RUSSELL,1997,Fawcett Books\n",
      "051513452X,The Lunatic Cafe (Anita Blake Vampire Hunter (Paperback)),Laurell K. Hamilton,2002,Jove Books\n",
      "0451206711,Orchid Blues (Holly Barker Novels (Paperback)),Stuart Woods,2002,Signet Book\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(random_samples[0].to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>book_year</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5087</th>\n",
       "      <td>0671019759</td>\n",
       "      <td>Dream Man</td>\n",
       "      <td>Linda Howard</td>\n",
       "      <td>1998</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         book_id book_title   book_author  book_year publisher\n",
       "5087  0671019759  Dream Man  Linda Howard       1998    Pocket"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[books['book_title']=='Dream Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"Genres\": [\"Fiction\", \"Non-Fiction\", \"Science Fiction\", \"Fantasy\", \"Mystery\", \"Thriller\", \"Romance\", \"Historical Fiction\", \"Biography\", \"Self-Help\", \"Children's\", \"Young Adult\", \"Humor\", \"Classics\", \"Poetry\", \"Graphic Novel\", \"Satire\", \"Urban Fantasy\", \"Dystopian\"],\n",
    "#   \"Formats\": [\"Hardcover\", \"Paperback\", \"Ebook\", \"Audiobook\"],\n",
    "#   \"Languages\": [\"English\", \"Spanish\", \"French\", \"German\", \"Chinese\", \"Japanese\", \"Korean\", \"Italian\", \"Portuguese\", \"Russian\", \"Other\"],\n",
    "#   \"Author Nationalities\": [\"American\", \"British\", \"Canadian\", \"Australian\", \"Indian\", \"Chinese\", \"Japanese\", \"French\", \"German\", \"Russian\", \"Italian\", \"Spanish\", \"Brazilian\", \"Mexican\", \"South African\", \"Other\"],\n",
    "#   \"Author Genders\": [\"Male\", \"Female\", \"Non-Binary\", \"Other\", \"Unknown\"],\n",
    "#   \"Publication Years\": [\"Pre-1900\", \"1900-1950\", \"1951-2000\", \"2001-2010\", \"2011-2020\", \"2021-Present\"],\n",
    "#   \"Book Lengths\": [\"Short Story\", \"Novella\", \"Novel\", \"Series\"],\n",
    "#   \"Page Counts\": [\"Less than 100\", \"100-200\", \"201-300\", \"301-400\", \"401-500\", \"More than 500\"],\n",
    "#   \"Audience Age Groups\": [\"Children\", \"Teens\", \"Adults\", \"Seniors\", \"All Ages\"],\n",
    "#   \"Reading Levels\": [\"Beginner\", \"Intermediate\", \"Advanced\"],\n",
    "#   \"Themes\": [\"Adventure\", \"Friendship\", \"Love\", \"War\", \"Crime\", \"Fantasy\", \"Science\", \"Religion\", \"Philosophy\", \"Politics\", \"History\", \"Technology\", \"Magic\", \"Travel\", \"Art\", \"Music\", \"Sports\", \"Family\", \"Identity\", \"Growth\", \"Ethics\", \"Nature\", \"Survival\", \"Courage\", \"Betrayal\", \"Justice\", \"Freedom\"],\n",
    "#   \"Settings\": [\"Contemporary\", \"Historical\", \"Future\", \"Alternate Reality\", \"Urban\", \"Rural\", \"Space\", \"Fantasy World\"],\n",
    "#   \"Ratings\": [\"1 Star\", \"2 Stars\", \"3 Stars\", \"4 Stars\", \"5 Stars\"],\n",
    "#   \"Popularity\": [\"Bestseller\", \"Popular\", \"Average\", \"Niche\"],\n",
    "#   \"Awards\": [\"Pulitzer Prize\", \"Man Booker Prize\", \"National Book Award\", \"Hugo Award\", \"Nebula Award\", \"None\"]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"Genres\": [\"Fiction\", \"Non-Fiction\", \"Science Fiction\", \"Fantasy\", \"Mystery\", \"Thriller\", \"Romance\", \"Historical Fiction\", \"Biography\", \"Self-Help\", \"Children's\", \"Young Adult\", \"Humor\", \"Classics\", \"Poetry\", \"Graphic Novel\", \"Satire\", \"Urban Fantasy\", \"Dystopian\"],\n",
    "    \"Themes\": [\"Adventure\", \"Friendship\", \"Love\", \"War\", \"Crime\", \"Fantasy\", \"Science\", \"Religion\", \"Philosophy\", \"Politics\", \"History\", \"Technology\", \"Magic\", \"Travel\", \"Art\", \"Music\", \"Sports\", \"Family\", \"Identity\", \"Growth\", \"Ethics\", \"Nature\", \"Survival\", \"Courage\", \"Betrayal\", \"Justice\", \"Freedom\"],\n",
    "    \"Audience Age Groups\": [\"Children\", \"Teens\", \"Adults\", \"Seniors\", \"All Ages\"],\n",
    "    \"Settings\": [\"Contemporary\", \"Historical\", \"Future\", \"Alternate Reality\", \"Urban\", \"Rural\", \"Space\", \"Fantasy World\"],\n",
    "    \"Popularity\": [\"Bestseller\", \"Popular\", \"Average\", \"Niche\"],\n",
    "    \"Languages\": [\"English\", \"Spanish\", \"French\", \"German\", \"Chinese\", \"Japanese\", \"Korean\", \"Italian\", \"Portuguese\", \"Russian\", \"Other\"],\n",
    "    \"Ratings\": [\"1 Star\", \"2 Stars\", \"3 Stars\", \"4 Stars\", \"5 Stars\"],\n",
    "    \"Formats\": [\"Hardcover\", \"Paperback\", \"Ebook\", \"Audiobook\"],\n",
    "    \"Publication Years\": [\"Pre-1900\", \"1900-1950\", \"1951-2000\", \"2001-2010\", \"2011-2020\", \"2021-Present\"],\n",
    "    \"Author Nationalities\": [\"American\", \"British\", \"Canadian\", \"Australian\", \"Indian\", \"Chinese\", \"Japanese\", \"French\", \"German\", \"Russian\", \"Italian\", \"Spanish\", \"Brazilian\", \"Mexican\", \"South African\", \"Haitian\", \"Other\"],\n",
    "    \"Author Genders\": [\"Male\", \"Female\", \"Non-Binary\", \"Other\", \"Unknown\"],\n",
    "    \"Book Lengths\": [\"Short Story\", \"Novella\", \"Novel\", \"Series\"],\n",
    "    \"Page Counts\": [\"Less than 100\", \"100-200\", \"201-300\", \"301-400\", \"401-500\", \"More than 500\"],\n",
    "    \"Reading Levels\": [\"Beginner\", \"Intermediate\", \"Advanced\"],\n",
    "    \"Awards\": [\"Pulitzer Prize\", \"Man Booker Prize\", \"National Book Award\", \"Hugo Award\", \"Nebula Award\", \"None\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the generated book taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "directory = 'outputs/'\n",
    "\n",
    "with open(directory + 'book_taxonomy_15feats_temp.json', 'r') as file:\n",
    "    temp_book_taxonomy = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for book, tax in temp_book_taxonomy.items():\n",
    "    try:\n",
    "        tax_dict = eval(tax)\n",
    "    except:\n",
    "        print(book, tax)\n",
    "        # try:\n",
    "        #     tax_dict = eval(tax.replace(\"'Children's'\", \"\\\"Children's\\\"\"))\n",
    "        # except:\n",
    "        #     print(book, tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Genres': ['Science Fiction'],\n",
       " 'Themes': ['Adventure', 'Philosophy', 'Identity'],\n",
       " 'Audience Age Groups': 'Teens',\n",
       " 'Settings': 'Future',\n",
       " 'Popularity': 'Bestseller',\n",
       " 'Languages': 'English',\n",
       " 'Formats': 'Paperback',\n",
       " 'Book Lengths': 'Novel',\n",
       " 'Publication Years': '1951-2000',\n",
       " 'Author Nationalities': 'American',\n",
       " 'Author Genders': 'Male',\n",
       " 'Page Counts': '301-400',\n",
       " 'Reading Levels': 'Intermediate',\n",
       " 'Awards': ['Hugo Award', 'Nebula Award'],\n",
       " 'Ratings': 'Unknown'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(temp_book_taxonomy['Speaker for the Dead (Ender Wiggins Saga (Paperback))'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_taxonomy = dict()\n",
    "\n",
    "for book, tax in temp_book_taxonomy.items():\n",
    "    tax_dict = eval(tax)\n",
    "    book_taxonomy[book] = tax_dict\n",
    "\n",
    "with open(\"processed_data/\" + 'book_taxonomy_15feats.json', 'w') as f:\n",
    "    json.dump(book_taxonomy, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the bert embeddings for each book name in the book_taxonomy\n",
    "# and store the embeddings in a dictionary where the key is the book name\n",
    "# see the python file 'calculate_bert_emb.py' for the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "directory = 'processed_data/'\n",
    "df_items = pd.read_csv(directory + 'item_mapping.csv')\n",
    "\n",
    "with open(directory + 'book_taxonomy_15feats.json', 'r') as file:\n",
    "    books_taxonomy = json.load(file)\n",
    "\n",
    "tax_values = []\n",
    "\n",
    "for index, row in df_items.iterrows():\n",
    "    book = row['book_title']\n",
    "    tax_values.append(books_taxonomy[book])\n",
    "\n",
    "df_items['book_taxonomy'] = tax_values\n",
    "df_items.to_csv(directory + 'item_mapping_tax_15feats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_book_tax(book_id, df_items):\n",
    "    '''\n",
    "    Input: book_id (int)\n",
    "    Output: a list of values for the book taxonomy of the given book_id\n",
    "    Note: need to get the df_items before running this method\n",
    "    '''\n",
    "    book_tax = df_items[df_items['book_id'] == book_id]['book_taxonomy'].values[0]\n",
    "    # string_dict = json.loads(book_tax)\n",
    "    string_dict = eval(book_tax)\n",
    "    value_list = []\n",
    "    for key in string_dict:\n",
    "        value_list.append(string_dict[key])\n",
    "    return value_list\n",
    "\n",
    "def history_to_json_nametax(input_path, output_path, item_mapping_path, taxonomy=False, sample=False):\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(input_path)\n",
    "    df_items = pd.read_csv(item_mapping_path)\n",
    "    # book_titles = df_items['book_title'].tolist()\n",
    "    # book_ids = df_items['book_id'].tolist()\n",
    "    # book_dict = dict(zip(book_ids, book_titles))\n",
    "    if sample:\n",
    "        data = data.sample(n=2000, random_state=42).reset_index(drop=True)\n",
    "        data.to_csv(output_path[:-5] + \".csv\", index=False)\n",
    "    json_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        # print(index)\n",
    "        row['history_item_id'] = eval(row['history_item_id'])\n",
    "        row['history_item_title'] = eval(row['history_item_title'])\n",
    "        L = len(row['history_item_id'])\n",
    "        history = \"The user has interacted with the following books before:\"\n",
    "\n",
    "        # target_item_name = \"\\\"\" + book_dict[int(row['item_id'])] + \"\\\"\"\n",
    "\n",
    "        if taxonomy: # taxonomy generation\n",
    "            history += \" {\"\n",
    "            for i in range(L):\n",
    "                # print(i)\n",
    "                # tax_value = get_book_tax(int(row['history_item_id'][i]), df_items)\n",
    "                tax_value = get_book_tax(str(row['history_item_id'][i]), df_items)\n",
    "\n",
    "                if i == 0:\n",
    "                    history += \"\\\"\" + row['history_item_title'][i] + \"\\\"\" + f\": {tax_value}\"\n",
    "                else:\n",
    "                    history += \", \\\"\" + row['history_item_title'][i] + \"\\\"\" + f\": {tax_value}\"\n",
    "            history += \"}\"\n",
    "            json_list.append({\n",
    "                \"input\": f\"{history}\\n\",\n",
    "                \"true_book\": str(row['item_title']),\n",
    "                \"true_book_id\": str(row['item_id']),\n",
    "                # \"true_book_time\": str(row['timestamp']),\n",
    "            })\n",
    "        \n",
    "        else: # direct generation\n",
    "            for i in range(L):\n",
    "                if i == 0:\n",
    "                    history += \" \\\"\" + row['history_item_title'][i] + \"\\\"\"\n",
    "                else:\n",
    "                    history += \", \\\"\" + row['history_item_title'][i] + \"\\\"\"\n",
    "            json_list.append({\n",
    "                # \"instruction\": \"Given a list of books the user has interacted before, please recommend a new book that aligns with the user's preferences. Output in dictionary with key \\\"recommendation\\\" and the corresponding recommended book, and don't give any explanation.\",\n",
    "                \"input\": f\"{history}\\n\",\n",
    "                \"true_book\": str(row['item_title']),\n",
    "                \"true_book_id\": str(row['item_id']),\n",
    "                # \"true_book_time\": str(row['timestamp']),\n",
    "            })\n",
    "        \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(json_list, f, indent=4)\n",
    "\n",
    "\n",
    "def history_to_json_tax(input_path, output_path, item_mapping_path, taxonomy=False, sample=False):\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(input_path)\n",
    "    df_items = pd.read_csv(item_mapping_path)\n",
    "    # book_titles = df_items['book_title'].tolist()\n",
    "    # book_ids = df_items['book_id'].tolist()\n",
    "    # book_dict = dict(zip(book_ids, book_titles))\n",
    "    if sample:\n",
    "        data = data.sample(n=2000, random_state=42).reset_index(drop=True)\n",
    "        data.to_csv(output_path[:-5] + \".csv\", index=False)\n",
    "    json_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        # print(index)\n",
    "        row['history_item_id'] = eval(row['history_item_id'])\n",
    "        row['history_item_title'] = eval(row['history_item_title'])\n",
    "        L = len(row['history_item_id'])\n",
    "        history = \"The user has interacted with the following books before:\"\n",
    "\n",
    "        # target_item_name = \"\\\"\" + book_dict[int(row['item_id'])] + \"\\\"\"\n",
    "\n",
    "        if taxonomy: # taxonomy generation\n",
    "            history += \" [\"\n",
    "            for i in range(L):\n",
    "                # print(i)\n",
    "                tax_value = get_book_tax(str(row['history_item_id'][i]), df_items)\n",
    "                if i == 0:\n",
    "                    history += f\"{tax_value}\"\n",
    "                else:\n",
    "                    history += \", \" + f\"{tax_value}\"\n",
    "            history += \"]\"\n",
    "            json_list.append({\n",
    "                \"input\": f\"{history}\\n\",\n",
    "                \"true_book\": str(row['item_title']),\n",
    "                \"true_book_id\": str(row['item_id']),\n",
    "                # \"true_book_time\": str(row['timestamp']),\n",
    "            })\n",
    "        \n",
    "        else: # direct generation\n",
    "            for i in range(L):\n",
    "                if i == 0:\n",
    "                    history += \" \\\"\" + row['history_item_title'][i] + \"\\\"\"\n",
    "                else:\n",
    "                    history += \", \\\"\" + row['history_item_title'][i] + \"\\\"\"\n",
    "            json_list.append({\n",
    "                # \"instruction\": \"Given a list of books the user has interacted before, please recommend a new book that aligns with the user's preferences. Output in dictionary with key \\\"recommendation\\\" and the corresponding recommended book, and don't give any explanation.\",\n",
    "                \"input\": f\"{history}\\n\",\n",
    "                \"true_book\": str(row['item_title']),\n",
    "                \"true_book_id\": str(row['item_id']),\n",
    "                # \"true_book_time\": str(row['timestamp']),\n",
    "            })\n",
    "        \n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(json_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'processed_data/'\n",
    "\n",
    "history_to_json_nametax(directory + 'data_2000.csv', directory + 'data_2000_dir.json', directory + 'item_mapping.csv', taxonomy=False, sample=False)\n",
    "\n",
    "history_to_json_nametax(directory + 'data_2000.csv', directory + 'data_2000_nametax_5feats.json', directory + 'item_mapping_tax_5feats.csv', taxonomy=True, sample=False)\n",
    "history_to_json_nametax(directory + 'data_2000.csv', directory + 'data_2000_nametax_10feats.json', directory + 'item_mapping_tax_10feats.csv', taxonomy=True, sample=False)\n",
    "\n",
    "history_to_json_tax(directory + 'data_2000.csv', directory + 'data_2000_tax_5feats.json', directory + 'item_mapping_tax_5feats.csv', taxonomy=True, sample=False)\n",
    "history_to_json_tax(directory + 'data_2000.csv', directory + 'data_2000_tax_10feats.json', directory + 'item_mapping_tax_10feats.csv', taxonomy=True, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'processed_data/'\n",
    "\n",
    "history_to_json_nametax(directory + 'data_2000.csv', directory + 'data_2000_nametax_15feats.json', directory + 'item_mapping_tax_15feats.csv', taxonomy=True, sample=False)\n",
    "\n",
    "history_to_json_tax(directory + 'data_2000.csv', directory + 'data_2000_tax_15feats.json', directory + 'item_mapping_tax_15feats.csv', taxonomy=True, sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a prompt sample\n",
    "# randomly choose one sample, for which the user_id is in all_sequential.csv but not in data_2000.csv\n",
    "\n",
    "import pandas as pd\n",
    "data_2000 = pd.read_csv('processed_data/data_2000.csv')\n",
    "all_sequential = pd.read_csv('processed_data/all_sequential.csv')\n",
    "\n",
    "data_2000_user_ids = set(data_2000['user_id'])\n",
    "all_sequential_user_ids = set(all_sequential['user_id'])\n",
    "\n",
    "prompt_user_ids = all_sequential_user_ids - data_2000_user_ids\n",
    "\n",
    "prompt_user_id = list(prompt_user_ids)[2]\n",
    "\n",
    "prompt_user_data = all_sequential[all_sequential['user_id'] == prompt_user_id]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_sample = prompt_user_data.sample(n=1, random_state=42).values[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval(prompt_sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt_sample(prompt_sample, item_mapping_path, taxonomy=False):\n",
    "    import pandas as pd\n",
    "    df_items = pd.read_csv(item_mapping_path)\n",
    "    book_names = df_items['book_title'].tolist()\n",
    "    book_ids = df_items['book_id'].tolist()\n",
    "    book_dict = dict(zip(book_ids, book_names))\n",
    "\n",
    "    # json_list = []\n",
    "    history_item_id = eval(prompt_sample[2])\n",
    "    history_item_title = eval(prompt_sample[1])\n",
    "    L = len(history_item_id)\n",
    "\n",
    "    target_item_id = prompt_sample[4]\n",
    "    target_item_title = book_dict[target_item_id]\n",
    "\n",
    "    if taxonomy: # taxonomy generation\n",
    "        for i in range(L):\n",
    "            # print(i)\n",
    "            tax_value = get_book_tax(str(history_item_id[i]), df_items)\n",
    "            if i == 0:\n",
    "                history = \"{\\\"\" + history_item_title[i] + \"\\\"\" + f\": {tax_value}\"\n",
    "            else:\n",
    "                history += \", \\\"\" + history_item_title[i] + \"\\\"\" + f\": {tax_value}\"\n",
    "        history += \"}\"\n",
    "        target_tax = get_book_tax(target_item_id, df_items)\n",
    "        target = \"\\\"\" + target_item_title + \"\\\"\" + f\": {target_tax}\"\n",
    "    \n",
    "    else: # direct generation\n",
    "        for i in range(L):\n",
    "            if i == 0:\n",
    "                history = \"\\\"\" + history_item_title[i] + \"\\\"\"\n",
    "            else:\n",
    "                history += \", \\\"\" + history_item_title[i] + \"\\\"\"\n",
    "        target = \"\\\"\" + target_item_title + \"\\\"\"\n",
    "    \n",
    "    return history, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history, target = get_prompt_sample(prompt_sample, 'processed_data/item_mapping.csv', taxonomy=False)\n",
    "history, target = get_prompt_sample(prompt_sample, 'processed_data/item_mapping_tax_15feats.csv', taxonomy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Patriot Games',\n",
       " 'The Pillars of the Earth',\n",
       " 'The Firm',\n",
       " 'Insomnia',\n",
       " 'Second Child',\n",
       " 'Skeleton Crew',\n",
       " 'The Stand: The Complete &amp; Uncut Edition',\n",
       " 'The Runaway Jury',\n",
       " 'The Client',\n",
       " 'The Pelican Brief']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(eval(history).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Thriller', 'Mystery'], ['Crime', 'Justice'], 'Adults', 'Contemporary', 'Bestseller', 'English', 'Hardcover', 'Novel', '1951-2000', 'American', 'Male', '301-400', 'Intermediate', 'None', 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print(eval(history)['The Pelican Brief'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Nathaniel\": [['Horror', 'Thriller'], ['Mystery', 'Supernatural', 'Family'], 'Adults', 'Contemporary', 'Average', 'English', 'Paperback', 'Novel', '1951-2000', 'American', 'Male', '301-400', 'Intermediate', 'None', 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Patriot Games\": [[\\'Thriller\\', \\'Fiction\\'], [\\'Adventure\\', \\'War\\', \\'Politics\\'], \\'Adults\\', \\'Contemporary\\', \\'Popular\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"The Pillars of the Earth\": [[\\'Historical Fiction\\'], [\\'Adventure\\', \\'Love\\', \\'War\\'], \\'Adults\\', \\'Historical\\', \\'Bestseller\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'British\\'], \"The Firm\": [[\\'Thriller\\', \\'Mystery\\'], [\\'Crime\\', \\'Justice\\'], \\'Adults\\', \\'Contemporary\\', \\'Bestseller\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"Insomnia\": [[\\'Horror\\', \\'Fantasy\\'], [\\'Psychological\\', \\'Supernatural\\', \\'Mystery\\'], \\'Adults\\', \\'Contemporary\\', \\'Bestseller\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"Second Child\": [[\\'Thriller\\', \\'Horror\\'], [\\'Mystery\\', \\'Family\\', \\'Crime\\'], \\'Adults\\', \\'Contemporary\\', \\'Popular\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"Skeleton Crew\": [[\\'Fiction\\', \\'Horror\\', \\'Thriller\\'], [\\'Adventure\\', \\'Survival\\', \\'Courage\\', \\'Betrayal\\'], \\'Adults\\', \\'Contemporary\\', \\'Bestseller\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"The Stand: The Complete &amp; Uncut Edition\": [[\\'Science Fiction\\', \\'Horror\\', \\'Fantasy\\'], [\\'Survival\\', \\'Good vs Evil\\', \\'Post-Apocalyptic\\'], \\'Adults\\', \\'Contemporary\\', \\'Bestseller\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"The Runaway Jury\": [[\\'Thriller\\', \\'Mystery\\'], [\\'Crime\\', \\'Justice\\'], \\'Adults\\', \\'Contemporary\\', \\'Bestseller\\', \\'English\\', \\'Hardcover\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"The Client\": [[\\'Thriller\\', \\'Mystery\\'], [\\'Crime\\', \\'Justice\\'], \\'Adults\\', \\'Contemporary\\', \\'Bestseller\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\'], \"The Pelican Brief\": [[\\'Thriller\\', \\'Mystery\\'], [\\'Crime\\', \\'Justice\\'], \\'Adults\\', \\'Contemporary\\', \\'Bestseller\\', \\'English\\', \\'Hardcover\\', \\'Novel\\', \\'1951-2000\\', \\'American\\']}'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Nathaniel\": [[\\'Horror\\', \\'Thriller\\'], [\\'Mystery\\', \\'Supernatural\\', \\'Family\\'], \\'Adults\\', \\'Contemporary\\', \\'Popular\\', \\'English\\', \\'Paperback\\', \\'Novel\\', \\'1951-2000\\', \\'American\\']'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
